---
id: "E05-T001"
title: "Files and storage limits schemas"
status: "todo"
priority: "critical"
labels: [backend, database, schema]
assignee: ""
workflow_state: "DRAFT"
epic: "E05"
depends_on: []
blocks: ["E05-T006", "E05-T009"]
breakpoint: false
assigned_agent: ""
created_at: "2026-01-13T00:00:00Z"
updated_at: "2026-01-13T00:00:00Z"
spec_file: ""
test_files: []
code_files: []
pr_url: ""
---

# E05-T001: Files and storage limits schemas

## Description

Define Drizzle ORM schemas for files table, user_storage_limits table (user-specific overrides), and extend groups.settings for role-based limits. Includes migrations, indexes, foreign keys, and audit fields following existing patterns.

## Acceptance Criteria

### Files Table
- [ ] AC1: files table with id, name, mime_type, size_bytes, storage_key, storage_backend
- [ ] AC2: Files table fields: uploaded_by (FK users), group_id (FK groups), entity_type, entity_id
- [ ] AC3: status field (varchar) with values: 'active', 'soft_deleted'
- [ ] AC4: Timestamps: created_at, updated_at (auto-updated via trigger), deleted_at (soft delete)
- [ ] AC5: Foreign keys: uploaded_by → users(id) CASCADE, group_id → groups(id) CASCADE
- [ ] AC6: Indexes on uploaded_by, group_id, status, (entity_type, entity_id)
- [ ] AC7: Unique index on storage_key

### User Storage Limits Table
- [ ] AC8: user_storage_limits table with id, user_id (unique FK to users)
- [ ] AC9: Fields: max_file_size_bytes, storage_quota_bytes (both nullable, NULL = use role/default)
- [ ] AC10: used_bytes field (bigint, not null, default 0) for quota tracking
- [ ] AC11: Audit fields: set_by (FK users), reason (text)
- [ ] AC12: Timestamps: created_at, updated_at (auto-updated via trigger)
- [ ] AC13: Foreign keys: user_id → users(id) CASCADE, set_by → users(id) SET NULL
- [ ] AC14: Unique constraint on user_id

### Group Settings Extension
- [ ] AC15: Document groups.settings JSONB structure for role-based limits
- [ ] AC16: Zod schema for validating limits structure in settings

### Migration
- [ ] AC17: Migration file 0010_create_files_and_limits.sql
- [ ] AC18: Migration includes updated_at trigger for both tables
- [ ] AC19: Down migration provided for rollback

### Types & Tests
- [ ] AC20: TypeScript types exported (File, NewFile, UserStorageLimit, NewUserStorageLimit)
- [ ] AC21: Tests verify schema constraints and relations
- [ ] AC22: Tests verify foreign key CASCADE behavior
- [ ] AC23: Tests verify unique constraints

## Technical Notes

### Files Schema Structure

```typescript
// packages/db/src/schema/files.ts

export const files = pgTable(
  'files',
  {
    id: uuid('id').primaryKey().defaultRandom(),
    name: varchar('name', { length: 255 }).notNull(),
    mimeType: varchar('mime_type', { length: 100 }).notNull(),
    sizeBytes: bigint('size_bytes', { mode: 'number' }).notNull(),
    storageKey: varchar('storage_key', { length: 500 }).notNull().unique(),
    storageBackend: varchar('storage_backend', { length: 50 }).notNull().default('s3'),
    uploadedBy: uuid('uploaded_by').notNull().references(() => users.id, { onDelete: 'cascade' }),
    groupId: uuid('group_id').references(() => groups.id, { onDelete: 'cascade' }),
    entityType: varchar('entity_type', { length: 50 }),
    entityId: uuid('entity_id'),
    status: varchar('status', { length: 20 }).notNull().default('active'),
    createdAt: timestamp('created_at', { withTimezone: true }).defaultNow().notNull(),
    updatedAt: timestamp('updated_at', { withTimezone: true }).defaultNow().notNull(),
    deletedAt: timestamp('deleted_at', { withTimezone: true }),
  },
  (table) => ({
    uploadedByIdx: index('files_uploaded_by_idx').on(table.uploadedBy),
    groupIdIdx: index('files_group_id_idx').on(table.groupId),
    entityIdx: index('files_entity_idx').on(table.entityType, table.entityId),
    statusIdx: index('files_status_idx').on(table.status),
    storageKeyIdx: index('files_storage_key_idx').on(table.storageKey),
  })
);

export type File = typeof files.$inferSelect;
export type NewFile = typeof files.$inferInsert;
```

### User Storage Limits Schema Structure

```typescript
// packages/db/src/schema/user-storage-limits.ts

export const userStorageLimits = pgTable(
  'user_storage_limits',
  {
    id: uuid('id').primaryKey().defaultRandom(),
    userId: uuid('user_id').notNull().unique().references(() => users.id, { onDelete: 'cascade' }),
    maxFileSizeBytes: bigint('max_file_size_bytes', { mode: 'number' }),
    storageQuotaBytes: bigint('storage_quota_bytes', { mode: 'number' }),
    usedBytes: bigint('used_bytes', { mode: 'number' }).notNull().default(0),
    setBy: uuid('set_by').references(() => users.id, { onDelete: 'set null' }),
    reason: text('reason'),
    createdAt: timestamp('created_at', { withTimezone: true }).defaultNow().notNull(),
    updatedAt: timestamp('updated_at', { withTimezone: true }).defaultNow().notNull(),
  },
  (table) => ({
    userIdIdx: index('user_storage_limits_user_id_idx').on(table.userId),
  })
);

export type UserStorageLimit = typeof userStorageLimits.$inferSelect;
export type NewUserStorageLimit = typeof userStorageLimits.$inferInsert;
```

### Groups Settings JSONB Structure

```typescript
// packages/core/src/schemas/group.schema.ts

export const groupLimitsSchema = z.object({
  limits: z.object({
    teacher: z.object({
      maxFileSizeBytes: z.number().int().positive(),
      storageQuotaBytes: z.number().int().positive(),
    }).optional(),
    student: z.object({
      maxFileSizeBytes: z.number().int().positive(),
      storageQuotaBytes: z.number().int().positive(),
    }).optional(),
  }).optional(),
});

// groups.settings JSONB example:
{
  "limits": {
    "teacher": {
      "maxFileSizeBytes": 52428800,      // 50MB
      "storageQuotaBytes": 5368709120     // 5GB
    },
    "student": {
      "maxFileSizeBytes": 10485760,       // 10MB
      "storageQuotaBytes": 1073741824     // 1GB
    }
  }
}
```

### Migration File

```sql
-- Migration: 0010_create_files_and_limits.sql

-- Create files table
CREATE TABLE "files" (
  "id" uuid PRIMARY KEY DEFAULT gen_random_uuid() NOT NULL,
  "name" varchar(255) NOT NULL,
  "mime_type" varchar(100) NOT NULL,
  "size_bytes" bigint NOT NULL,
  "storage_key" varchar(500) NOT NULL UNIQUE,
  "storage_backend" varchar(50) NOT NULL DEFAULT 's3',
  "uploaded_by" uuid NOT NULL,
  "group_id" uuid,
  "entity_type" varchar(50),
  "entity_id" uuid,
  "status" varchar(20) NOT NULL DEFAULT 'active',
  "created_at" timestamp with time zone DEFAULT now() NOT NULL,
  "updated_at" timestamp with time zone DEFAULT now() NOT NULL,
  "deleted_at" timestamp with time zone
);

-- Create user storage limits table
CREATE TABLE "user_storage_limits" (
  "id" uuid PRIMARY KEY DEFAULT gen_random_uuid() NOT NULL,
  "user_id" uuid NOT NULL UNIQUE,
  "max_file_size_bytes" bigint,
  "storage_quota_bytes" bigint,
  "used_bytes" bigint NOT NULL DEFAULT 0,
  "set_by" uuid,
  "reason" text,
  "created_at" timestamp with time zone DEFAULT now() NOT NULL,
  "updated_at" timestamp with time zone DEFAULT now() NOT NULL
);

-- Add foreign key constraints
ALTER TABLE "files"
  ADD CONSTRAINT "files_uploaded_by_users_id_fk"
  FOREIGN KEY ("uploaded_by") REFERENCES "public"."users"("id") ON DELETE cascade;

ALTER TABLE "files"
  ADD CONSTRAINT "files_group_id_groups_id_fk"
  FOREIGN KEY ("group_id") REFERENCES "public"."groups"("id") ON DELETE cascade;

ALTER TABLE "user_storage_limits"
  ADD CONSTRAINT "user_storage_limits_user_id_users_id_fk"
  FOREIGN KEY ("user_id") REFERENCES "public"."users"("id") ON DELETE cascade;

ALTER TABLE "user_storage_limits"
  ADD CONSTRAINT "user_storage_limits_set_by_users_id_fk"
  FOREIGN KEY ("set_by") REFERENCES "public"."users"("id") ON DELETE set null;

-- Create indexes
CREATE INDEX "files_uploaded_by_idx" ON "files" USING btree ("uploaded_by");
CREATE INDEX "files_group_id_idx" ON "files" USING btree ("group_id");
CREATE INDEX "files_entity_idx" ON "files" USING btree ("entity_type", "entity_id");
CREATE INDEX "files_status_idx" ON "files" USING btree ("status");
CREATE INDEX "files_storage_key_idx" ON "files" USING btree ("storage_key");

CREATE INDEX "user_storage_limits_user_id_idx" ON "user_storage_limits" USING btree ("user_id");

-- Create triggers for updated_at auto-update
CREATE TRIGGER update_files_updated_at
  BEFORE UPDATE ON files
  FOR EACH ROW
  EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_user_storage_limits_updated_at
  BEFORE UPDATE ON user_storage_limits
  FOR EACH ROW
  EXECUTE FUNCTION update_updated_at_column();
```

## Out of Scope

- Service layer logic (E05-T006)
- API routes (E05-T007, E05-T008)
- Storage backend implementations (E05-T003, E05-T004, E05-T005)
- File upload handling (E05-T007)

## History

| Date | State | Agent | Notes |
| ---- | ----- | ----- | ----- |
| 2026-01-13 | DRAFT | pm | Task created for Epic E05 |
