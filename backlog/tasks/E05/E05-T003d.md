---
id: "E05-T003d"
title: "Production S3 credentials and validation"
status: "todo"
priority: "high"
task_type: "backend"
workflow: "infrastructure"
labels: [infrastructure, s3, production, credentials]
assignee: ""
workflow_state: "DRAFT"
epic: "E05"
agentic_style: "outcome-focused"
depends_on: ["E05-T003a", "E05-T003c"]
blocks: []
breakpoint: true
assigned_agent: ""
created_at: "2026-01-16T00:00:00Z"
updated_at: "2026-01-16T00:00:00Z"
spec_file: ""
test_files: []
code_files: []
pr_url: ""
---

# E05-T003d: Production S3 credentials and validation

## Description

Obtain production S3 credentials from the user, configure them securely, and validate the S3 backend works with real cloud storage. This ensures the storage system is production-ready before building features on top of it.

## Why This Matters

MinIO testing proves the code works with S3-compatible APIs, but production S3 (AWS, DigitalOcean Spaces, Backblaze B2, etc.) may have subtle differences in behavior, permissions, or networking. Validating with real credentials prevents surprises at deployment time.

## Acceptance Criteria

- [ ] AC1: User provides S3-compatible service credentials (endpoint, bucket, access key, secret key)
- [ ] AC2: Credentials are stored securely in .env (not committed to git)
- [ ] AC3: Validation script tests: connectivity, bucket access, upload, download, delete, signed URL
- [ ] AC4: Validation script produces clear pass/fail output with helpful error messages
- [ ] AC5: CORS is configured on the bucket (if needed for signed URL downloads from browser)
- [ ] AC6: Bucket lifecycle policies are documented (for soft-delete cleanup)
- [ ] AC7: Documentation covers credential rotation procedure
- [ ] AC8: Production environment variables are documented in deployment guide

## Constraints

- **BREAKPOINT:** This task requires user interaction to provide credentials
- Credentials must never be logged or exposed in error messages
- Validation must be non-destructive (use test prefix for files, clean up after)
- Must support multiple S3-compatible providers (not AWS-specific)
- Must validate both path-style and virtual-hosted style URLs work

## Workflow

**Category:** `infrastructure`

**Rationale:** Credential setup requires user interaction and manual validation - not suitable for automated TDD.

**Phases:**
1. `/analyze` - Research S3 provider options and credential formats
2. Human provides credentials (BREAKPOINT - user interaction required)
3. `/implement` - Create validation script and update .env.example
4. Human runs validation script with their credentials
5. `/review-code` - Verify script doesn't leak credentials
6. `/update-docs` - Document S3 setup in deployment guide
7. PR creation (without credentials)

## User Interaction Required

**When this task is started, Claude should ask:**

> To validate S3 storage works in production, I need your S3-compatible service credentials. Please provide:
>
> 1. **Provider**: AWS S3, DigitalOcean Spaces, Backblaze B2, Cloudflare R2, or other?
> 2. **Endpoint URL**: (e.g., `https://s3.us-east-1.amazonaws.com` or `https://nyc3.digitaloceanspaces.com`)
> 3. **Region**: (e.g., `us-east-1`, `nyc3`)
> 4. **Bucket name**: The bucket you've created for RaptScallions
> 5. **Access Key ID**: Your access key
> 6. **Secret Access Key**: Your secret key
>
> I'll store these in your local `.env` file (which is gitignored) and run validation tests.
>
> **Note:** If you don't have an S3 provider yet, I can help you choose one:
> - **AWS S3**: Most compatible, pay-per-use, $0.023/GB/month
> - **DigitalOcean Spaces**: Simple pricing, $5/month for 250GB
> - **Backblaze B2**: Cheapest, $0.006/GB/month, S3-compatible API
> - **Cloudflare R2**: No egress fees, $0.015/GB/month

## Out of Scope

- S3 backend code (E05-T003a)
- MinIO local setup (E05-T003b)
- Automated credential provisioning (e.g., Terraform)
- Multi-region replication
- Backup/disaster recovery configuration
- CDN setup for file serving

## Context

- Uses S3 backend from E05-T003a
- After validation, this unblocks confident deployment
- Different providers may need different configurations:
  - AWS S3: virtual-hosted style URLs, region-specific endpoints
  - DigitalOcean Spaces: path-style URLs, specific endpoint format
  - Backblaze B2: S3-compatible API endpoint, specific region codes
- CORS configuration varies by provider (some require bucket policy, others use UI)

## History

| Date | State | Agent | Notes |
| ---- | ----- | ----- | ----- |
| 2026-01-16 | DRAFT | pm | New task created to ensure production S3 validation |
