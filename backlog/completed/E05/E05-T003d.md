---
id: "E05-T003d"
title: "Production S3 credentials and validation"
status: "done"
priority: "high"
task_type: "backend"
workflow: "infrastructure"
labels: [infrastructure, s3, production, credentials]
assignee: "developer"
workflow_state: "DONE"
completed_at: "2026-01-18T00:00:00Z"
analysis_file: "backlog/docs/analysis/E05/E05-T003d-analysis.md"
spec_file: "backlog/docs/specs/E05/E05-T003d-spec.md"
epic: "E05"
agentic_style: "outcome-focused"
depends_on: ["E05-T003a", "E05-T003c"]
blocks: []
breakpoint: true
assigned_agent: "developer"
created_at: "2026-01-16T00:00:00Z"
updated_at: "2026-01-18T00:00:00Z"
test_files: []
code_files:
  - scripts/validate-s3.ts
  - apps/docs/src/storage/patterns/production-s3-setup.md
  - apps/docs/src/.vitepress/config.ts
  - package.json
pr_url: ""
---

# E05-T003d: Production S3 credentials and validation

## Description

Obtain production S3 credentials from the user, configure them securely, and validate the S3 backend works with real cloud storage. This ensures the storage system is production-ready before building features on top of it.

## Why This Matters

MinIO testing proves the code works with S3-compatible APIs, but production S3 (AWS, DigitalOcean Spaces, Backblaze B2, etc.) may have subtle differences in behavior, permissions, or networking. Validating with real credentials prevents surprises at deployment time.

## Acceptance Criteria

- [x] AC1: User provides S3-compatible service credentials (endpoint, bucket, access key, secret key)
- [x] AC2: Credentials are stored securely in .env (not committed to git)
- [x] AC3: Validation script tests: connectivity, bucket access, upload, download, delete, signed URL
- [x] AC4: Validation script produces clear pass/fail output with helpful error messages
- [x] AC5: CORS is configured on the bucket (if needed for signed URL downloads from browser)
- [x] AC6: Bucket lifecycle policies are documented (for soft-delete cleanup)
- [x] AC7: Documentation covers credential rotation procedure
- [x] AC8: Production environment variables are documented in deployment guide

## Constraints

- **BREAKPOINT:** This task requires user interaction to provide credentials
- Credentials must never be logged or exposed in error messages
- Validation must be non-destructive (use test prefix for files, clean up after)
- Must support multiple S3-compatible providers (not AWS-specific)
- Must validate both path-style and virtual-hosted style URLs work

## Workflow

**Category:** `infrastructure`

**Rationale:** Credential setup requires user interaction and manual validation - not suitable for automated TDD.

**Phases:**
1. `/analyze` - Research S3 provider options and credential formats
2. Human provides credentials (BREAKPOINT - user interaction required)
3. `/implement` - Create validation script and update .env.example
4. Human runs validation script with their credentials
5. `/review-code` - Verify script doesn't leak credentials
6. `/update-docs` - Document S3 setup in deployment guide
7. PR creation (without credentials)

## User Interaction Required

**When this task is started, Claude should ask:**

> To validate S3 storage works in production, I need your S3-compatible service credentials. Please provide:
>
> 1. **Provider**: AWS S3, DigitalOcean Spaces, Backblaze B2, Cloudflare R2, or other?
> 2. **Endpoint URL**: (e.g., `https://s3.us-east-1.amazonaws.com` or `https://nyc3.digitaloceanspaces.com`)
> 3. **Region**: (e.g., `us-east-1`, `nyc3`)
> 4. **Bucket name**: The bucket you've created for RaptScallions
> 5. **Access Key ID**: Your access key
> 6. **Secret Access Key**: Your secret key
>
> I'll store these in your local `.env` file (which is gitignored) and run validation tests.
>
> **Note:** If you don't have an S3 provider yet, I can help you choose one:
> - **AWS S3**: Most compatible, pay-per-use, $0.023/GB/month
> - **DigitalOcean Spaces**: Simple pricing, $5/month for 250GB
> - **Backblaze B2**: Cheapest, $0.006/GB/month, S3-compatible API
> - **Cloudflare R2**: No egress fees, $0.015/GB/month

## Out of Scope

- S3 backend code (E05-T003a)
- MinIO local setup (E05-T003b)
- Automated credential provisioning (e.g., Terraform)
- Multi-region replication
- Backup/disaster recovery configuration
- CDN setup for file serving

## Context

- Uses S3 backend from E05-T003a
- After validation, this unblocks confident deployment
- Different providers may need different configurations:
  - AWS S3: virtual-hosted style URLs, region-specific endpoints
  - DigitalOcean Spaces: path-style URLs, specific endpoint format
  - Backblaze B2: S3-compatible API endpoint, specific region codes
- CORS configuration varies by provider (some require bucket policy, others use UI)

## Reviews

| Review Type | Verdict | Date | Link |
| ----------- | ------- | ---- | ---- |
| Code Review | APPROVED | 2026-01-18 | [E05-T003d-code-review.md](../../docs/reviews/E05/E05-T003d-code-review.md) |
| QA Review | PASSED | 2026-01-18 | [E05-T003d-qa-report.md](../../docs/reviews/E05/E05-T003d-qa-report.md) |

## History

| Date | State | Agent | Notes |
| ---- | ----- | ----- | ----- |
| 2026-01-16 | DRAFT | pm | New task created to ensure production S3 validation |
| 2026-01-18 | ANALYZED | analyst | Analysis complete with 3 approaches. Recommended: Approach A (Standalone Validation Script) |
| 2026-01-18 | APPROVED | architect | Implementation spec created. Selected Approach A (Standalone Validation Script). Ready for implementation after user provides credentials. |
| 2026-01-18 | IMPLEMENTED | developer | Created validation script (`scripts/validate-s3.ts`) with 8 tests: config, connectivity, upload, download, signed URL GET/PUT, delete, cleanup. Added `pnpm validate:s3` command. Created comprehensive production S3 documentation in KB with provider-specific setup (AWS, DO, Backblaze, Cloudflare R2), CORS config, lifecycle policies, and credential rotation. All 8 tests pass against AWS S3. |
| 2026-01-18 | CODE_REVIEW | reviewer | Code review APPROVED. Clean implementation, all TypeScript checks pass (1798 tests), no `any` types, follows conventions. Minor non-blocking suggestions: URL validation in error paths, debug mode not implemented. |
| 2026-01-18 | QA_REVIEW | qa | QA PASSED. All 8 acceptance criteria verified. Validation script tests all operations (config, connectivity, upload, download, signed URL GET/PUT, delete, cleanup). Documentation comprehensive with CORS, lifecycle, credential rotation for 4 providers. TypeScript passes, lint passes, 1798 tests pass. |
| 2026-01-18 | DONE | writer | Documentation updates complete. Updated production-s3-setup.md with source file links and spec references. Updated storage/index.md with Production S3 Setup link and E05-T003d reference. Task archived to completed. |

## Documentation Updates

**Writer:** writer
**Date:** 2026-01-18

### Files Updated

| File | Changes |
| ---- | ------- |
| `apps/docs/src/storage/patterns/production-s3-setup.md` | Added spec links for E05-T003a/b/c, added E05-T003c task reference, added Source Files section with GitHub links |
| `apps/docs/src/storage/index.md` | Added Production S3 Setup to Patterns section, added E05-T003d and E05-T003c to Implementation references, fixed E05-T003a path |

### Files Created

None

### Summary

The documentation for E05-T003d was already comprehensive. The production-s3-setup.md KB page created during implementation covers all aspects: provider comparison, setup instructions for AWS/DigitalOcean/Backblaze/Cloudflare R2, CORS configuration, lifecycle policies, credential rotation, and validation. Updates focused on:

1. Adding missing spec links for cross-referencing
2. Including the E05-T003c (MinIO integration tests) task reference
3. Adding Source Files section with direct GitHub links to implementation code
4. Ensuring the storage overview page includes the new documentation

### Verification

- [x] All code references are accurate
- [x] Examples are runnable (validation script tested against AWS S3)
- [x] Links point to correct locations (completed/ not tasks/)
- [x] Formatting is consistent with KB patterns
